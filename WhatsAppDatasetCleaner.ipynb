{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "WhatsAppDataset.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "L81S0nkvBIoT"
   },
   "source": [
    "# Cleaning whatsapp chat message backup to generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "l2_edyrOBIoW"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Ju6eL-H-BIoX"
   },
   "source": [
    "# loading the data\n",
    "data_file_raw = np.array([])\n",
    "with open(\"source_full.txt\",\"r\",encoding=\"utf-8\") as data_file:\n",
    "    i = 0\n",
    "    for line in data_file:\n",
    "        if i>1:\n",
    "            break\n",
    "        data_file_raw = np.append(data_file_raw,[line])"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O_5L2-152Xsf"
   },
   "source": [
    "np.random.shuffle(data_file_raw)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vMMLZ8uROQyZ"
   },
   "source": [
    "def remove_noice(text):\n",
    "  # removing non letter sequences\n",
    "  text = re.sub(r'(?=\\s|^)([^a-zA-Z]+)(?=\\s|$)',\"\",text)\n",
    "  # removing web addresses\n",
    "  text = re.sub(r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\",\"\",text)\n",
    "  # removing new lines\n",
    "  text.replace(\"\\n\",\" \")\n",
    "  # removing new line like character sequences\n",
    "  text.replace(\"\\\\n\",\" \")\n",
    "  # replacing multiple spaces with single space\n",
    "  text = re.sub(r\"\\s\\s+\",\" \",text)\n",
    "  # removing emojis\n",
    "  text = re.sub(emoji.get_emoji_regexp(),r\"\",text)\n",
    "  # removing non letter,number or space characters\n",
    "  text = re.sub(r'[^a-zA-Z\\s0-9]',\"\",text)\n",
    "  # removing leading and tailing white spaces and returning\n",
    "  return text.strip()"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "XRO-MYijBIoY"
   },
   "source": [
    "filtered_stage_1 = []\n",
    "# reformat multi lines\n",
    "i = -1\n",
    "for index,line in enumerate(data_file_raw):\n",
    "  line = line.strip()\n",
    "  # removing zero length empty spaces\n",
    "  line = (line.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
    "  # catching leading part of whatsapp message record syntax to check if line is\n",
    "  # the start of a new message or a new line of another message\n",
    "  matched = re.match(r\"(?:^\\d+/\\d+/\\d+,.\\d+:\\d+.(?:AM|PM).-(?:.+):)(.+)\",line)\n",
    "  if matched: # new message\n",
    "    sentence = matched.group(1)\n",
    "    sentence = remove_noice(sentence)\n",
    "    filtered_stage_1.append(sentence)\n",
    "    i+=1\n",
    "  else: # new line of previous message\n",
    "    line = remove_noice(line)\n",
    "    if len(line)==0:\n",
    "      pass\n",
    "    # new line of previous message is appended to previous message\n",
    "    filtered_stage_1[i]+=line"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'emoji' has no attribute 'get_emoji_regexp'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_56928/4149297658.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mmatched\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;31m# new message\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0msentence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmatched\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m     \u001B[0msentence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mremove_noice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m     \u001B[0mfiltered_stage_1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msentence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[0mi\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_56928/2707005568.py\u001B[0m in \u001B[0;36mremove_noice\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m     11\u001B[0m   \u001B[0mtext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mre\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msub\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr\"\\s\\s+\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\" \"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m   \u001B[1;31m# removing emojis\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m   \u001B[0mtext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mre\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msub\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0memoji\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_emoji_regexp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34mr\"\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m   \u001B[1;31m# removing non letter,number or space characters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m   \u001B[0mtext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mre\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msub\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mr'[^a-zA-Z\\s0-9]'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'emoji' has no attribute 'get_emoji_regexp'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Z7cWDnq8ff"
   },
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6OmW3ZiBq6Vi"
   },
   "source": [
    "#removing single word sentences\n",
    "filtered_stage_2 = filter(lambda x: len(re.split(r'[.,:\\s+]',x))>1,filtered_stage_1)\n",
    "\n",
    "#removing duplicates\n",
    "filtered_stage_3 = list(set(filtered_stage_2))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLfBmdivGBq5",
    "outputId": "c3c2e677-411e-4347-90d3-9c765ea7d6db"
   },
   "source": [
    "df = pd.DataFrame( filtered_stage_3,columns=['Message text'])\n",
    "print(df)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vpRK6FP9H0bT"
   },
   "source": [
    "df.to_excel(\"data_frame.xlsx\",sheet_name=\"Whatsapp\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0XXrBHUBq77B"
   },
   "source": [
    "with open(\"out.txt\",\"w+\",encoding=\"utf-8\") as out_file:\n",
    "  out_file.writelines(\"\\n\".join(filtered_stage_3))\n",
    "  out_file.close()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}